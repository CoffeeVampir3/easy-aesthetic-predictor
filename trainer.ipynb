{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe49dfb-c5f6-4a4d-8f03-bf82649faec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import convnext_base\n",
    "import torch.nn as nn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e88b3-f5f5-43bd-819e-f60d73951d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('untrained_aesthetic_scorer.pth').to('cuda')\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02c99b6a-5d06-4e18-9222-d99c048d3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "class ScoredImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the score folders.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Load all images\n",
    "        for score in os.listdir(root_dir):\n",
    "            score_dir = os.path.join(root_dir, score)\n",
    "            if not os.path.isdir(score_dir):\n",
    "                continue  # Skip non-directories\n",
    "            for img_name in os.listdir(score_dir):\n",
    "                if img_name.lower().endswith(('.jpg', '.png')):\n",
    "                    img_path = os.path.join(score_dir, img_name)\n",
    "                    if os.path.isfile(img_path):\n",
    "                        self.images.append(img_path)\n",
    "                        self.labels.append(float(score))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            try:\n",
    "                img_path = self.images[idx]\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "                break  # Success, exit the loop\n",
    "            except:\n",
    "                print(f\"Skipping unreadable image: {img_path}\")\n",
    "                idx = (idx + 1) % len(self.images) \n",
    "                \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84cec9f6-eb5a-40f8-9fa2-0939e5bcfe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Assuming ConvNeXt base model input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = ScoredImageDataset(root_dir=\"data\", transform=transform)\n",
    "\n",
    "# Determine sizes for splitting\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec5586c-c3db-460c-b9f5-d5a611977253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_dataloader, model, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    total_close_guesses = 0  # To track the number of close guesses\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients for evaluation\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Calculate the total loss\n",
    "            total_loss += loss.item() * inputs.size(0)  # Multiply by batch size\n",
    "\n",
    "            # Calculate close guesses\n",
    "            close_guesses = (outputs - labels).abs() <= 1.0  # Boolean tensor where close guesses are True\n",
    "            total_close_guesses += close_guesses.sum().item()\n",
    "\n",
    "            total_count += inputs.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_count\n",
    "    close_guess_accuracy = total_close_guesses / total_count  # Calculate the percentage of close guesses\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Close Guess Accuracy: {close_guess_accuracy:.4f}\")\n",
    "\n",
    "    # If you also want to calculate RMSE\n",
    "    rmse = torch.sqrt(torch.tensor(avg_loss))\n",
    "    print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8c75d-cafc-4fc2-b784-20a508cd03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "#3rd epoch increased lr by 10x\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.000001)\n",
    "\n",
    "lr = 0.00001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"Starting training run: lr={lr}\")\n",
    "\n",
    "for epoch in range(30):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_duration = time.time() - start_time  # Calculate the duration of the epoch\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {loss.item()}, Duration: {epoch_duration:.2f} seconds\")\n",
    "    evaluate_model(test_dataloader, model, criterion)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c92ceed-3436-4494-818f-5bf1b0f519b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 12\n",
    "torch.save(model.state_dict(), f'trained_aesthetic_scorer_{nepochs}_statedict.pth')\n",
    "torch.save(model, f'trained_aesthetic_scorer_{nepochs}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d62f8305-0e81-4dbe-add7-7acfde70d0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "def predict_image(model, img_path):\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    # Define the transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels\n",
    "        transforms.ToTensor(),  # Convert the image to a tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "    ])\n",
    "\n",
    "    image_tensor = transform(image)\n",
    "    \n",
    "    # Unsqueeze to add a batch dimension\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(\"cuda\")\n",
    "    \n",
    "    # Make sure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "\n",
    "    return output.item()\n",
    "\n",
    "pred = predict_image(model, \"/home/blackroot/Downloads/a.jpg\")\n",
    "print(round(pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
